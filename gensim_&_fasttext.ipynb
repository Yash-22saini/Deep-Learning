{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ou73OcbYdcf9"
      },
      "outputs": [],
      "source": [
        "# !pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gensim\n",
        "\n",
        "#   What it is: A Python library for topic modeling, similarity retrieval, and vector space modeling.\n",
        "\n",
        "#Popular models inside it:\n",
        "\n",
        "#   Word2Vec\n",
        "\n",
        "#   Doc2Vec\n",
        "\n",
        "#   FastText (yes, gensim also provides a wrapper for FastText)\n",
        "\n",
        "#   LDA (Latent Dirichlet Allocation) for topic modeling\n",
        "\n",
        "#   Main Uses:\n",
        "\n",
        "#   Build word embeddings (Word2Vec, FastText)\n",
        "\n",
        "#   Document embeddings (Doc2Vec)\n",
        "\n",
        "#   Topic modeling (LDA, LSI, HDP)\n",
        "\n",
        "#   Similarity queries (e.g., \"most similar words\")\n",
        "\n",
        "#   Key Features:\n",
        "\n",
        "#   Lightweight, memory-efficient\n",
        "\n",
        "#   Easy to integrate with NLP pipelines\n",
        "\n",
        "#   Handles large text corpora using streaming & efficient implementations\n",
        "\n",
        "#   ðŸ”¹ FastText\n",
        "\n",
        "#   What it is: A specific model created by Facebook AI Research (FAIR) for word embeddings and text classification.\n",
        "\n",
        "#   Unique Approach:\n",
        "\n",
        "#   Unlike Word2Vec, it represents a word as a bag of character n-grams.\n",
        "\n",
        "#   Example: \"playing\" â†’ \"play\", \"lay\", \"ying\", etc.\n",
        "\n",
        "#   This helps it understand morphology (word structure).\n",
        "\n",
        "#  Main Uses:\n",
        "\n",
        "#   Word embeddings (handles out-of-vocabulary (OOV) words better than Word2Vec)\n",
        "\n",
        "#   Text classification (very fast, works with large datasets)\n",
        "\n",
        "#   Key Features:\n",
        "\n",
        "#   Great at handling rare words / OOV words (like \"playyyy\" or \"plaiing\")\n",
        "\n",
        "#   Faster training than Word2Vec\n",
        "\n",
        "#   Pretrained embeddings available in many languages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykAnHKlcd6FJ",
        "outputId": "bab92298-95b2-4198-866f-76427c8f3b63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector for 'love':\n",
            "[-0.01723938  0.00733148  0.01037977  0.01148388  0.01493384 -0.01233535\n",
            "  0.00221123  0.01209456 -0.0056801  -0.01234705 -0.00082045 -0.0167379\n",
            " -0.01120002  0.01420908  0.00670508  0.01445134  0.01360049  0.01506148\n",
            " -0.00757831 -0.00112361  0.00469675 -0.00903806  0.01677746 -0.01971633\n",
            "  0.01352928  0.00582883 -0.00986566  0.00879638 -0.00347915  0.01342277\n",
            "  0.0199297  -0.00872489 -0.00119868 -0.01139127  0.00770164  0.00557325\n",
            "  0.01378215  0.01220219  0.01907699  0.01854683  0.01579614 -0.01397901\n",
            " -0.01831173 -0.00071151 -0.00619968  0.01578863  0.01187715 -0.00309133\n",
            "  0.00302193  0.00358008]\n",
            "\n",
            "Most similar to 'machine':\n",
            "[('fun', 0.12486250698566437), ('natural', 0.08055731654167175), ('embeddings', 0.07399576157331467), ('learning', 0.04237300902605057), ('is', 0.018277151510119438), ('love', 0.011071980930864811), ('word2vec', 0.0013571369927376509), ('language', -0.1094222441315651), ('creates', -0.11910455673933029), ('i', -0.17424818873405457)]\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Import library\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Step 2: Create a small dataset (tokenized sentences)\n",
        "sentences = [\n",
        "    [\"i\", \"love\", \"natural\", \"language\", \"processing\"],\n",
        "    [\"word2vec\", \"creates\", \"word\", \"embeddings\"],\n",
        "    [\"machine\", \"learning\", \"is\", \"fun\"],\n",
        "    [\"i\", \"love\", \"machine\", \"learning\"]\n",
        "]\n",
        "\n",
        "# Step 3: Train Word2Vec model\n",
        "model = Word2Vec(sentences, vector_size=50, window=3, min_count=1, sg=1)\n",
        "\n",
        "# Step 4: Get vector for a word\n",
        "print(\"Vector for 'love':\")\n",
        "print(model.wv['love'])\n",
        "\n",
        "# Step 5: Find most similar words\n",
        "print(\"\\nMost similar to 'machine':\")\n",
        "print(model.wv.most_similar('machine'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yW8A7WWEd_LT",
        "outputId": "731682ec-09a2-45e8-dcb4-82ec98577eb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector for 'love':\n",
            "[ 0.0001016   0.0022412  -0.00336715 -0.00033085 -0.00387935 -0.00419755\n",
            " -0.00151996 -0.00087366  0.00622636 -0.00660398 -0.00371136 -0.0065105\n",
            " -0.00377819  0.0010506  -0.00381672 -0.00034082  0.00088526  0.00218162\n",
            " -0.0022804   0.00038835  0.00569094  0.00153093  0.00135464 -0.00223462\n",
            " -0.00252768  0.00366243 -0.00188376 -0.0065851   0.00077982  0.00158725\n",
            " -0.00045243 -0.00435207 -0.00471068  0.00685046 -0.00293258 -0.00189113\n",
            " -0.0010784  -0.00111529  0.00011267 -0.00160898 -0.00335323  0.00489591\n",
            "  0.00278897  0.00365879 -0.00198696 -0.00063323 -0.00035158 -0.00079444\n",
            " -0.00180542  0.00361628]\n",
            "\n",
            "Vector for unseen word 'lovely':\n",
            "[ 1.0996094e-03 -1.4329599e-03  6.4024061e-04 -4.6484624e-03\n",
            " -3.2252874e-03 -3.2272032e-03 -5.2106446e-03  7.3700161e-05\n",
            " -2.5065436e-03 -4.3827746e-04 -8.6720131e-04 -2.0282581e-03\n",
            " -5.2141231e-03 -1.7155211e-03 -2.9054082e-03 -4.3657396e-04\n",
            "  1.4546837e-03 -5.4090080e-04  3.5679985e-03  1.3004243e-03\n",
            "  5.2754241e-03  2.4784237e-04 -1.3635936e-03 -1.5540116e-03\n",
            " -1.5275896e-03  3.4124113e-03 -2.3878645e-04  2.3212726e-03\n",
            "  1.5582581e-03 -3.3380801e-04 -1.1730569e-03 -1.3864449e-03\n",
            "  1.2645918e-03  1.5967959e-03 -1.2594805e-03  2.9329176e-03\n",
            " -1.9585257e-03  3.2267077e-03 -1.3967685e-03 -1.0921702e-03\n",
            " -2.9363038e-03  1.6972146e-03  4.7628628e-03  3.2595536e-03\n",
            "  1.2487751e-03  1.2574653e-03  1.2528071e-03  5.3581648e-04\n",
            "  8.6534722e-04 -1.1097800e-04]\n",
            "\n",
            "Most similar to 'machine':\n",
            "[('rare', 0.39224502444267273), ('handles', 0.1692541241645813), ('words', 0.07193600386381149), ('language', 0.03809293359518051), ('i', 0.03597959503531456), ('processing', 0.03174527734518051), ('fun', 0.0277476254850626), ('natural', -0.019410915672779083), ('fasttext', -0.05160867050290108), ('learning', -0.21739400923252106)]\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Import FastText\n",
        "from gensim.models import FastText\n",
        "\n",
        "# Step 2: Create dataset\n",
        "sentences = [\n",
        "    [\"i\", \"love\", \"natural\", \"language\", \"processing\"],\n",
        "    [\"fasttext\", \"handles\", \"rare\", \"words\"],\n",
        "    [\"machine\", \"learning\", \"is\", \"fun\"],\n",
        "    [\"i\", \"love\", \"machine\", \"learning\"]\n",
        "]\n",
        "\n",
        "# Step 3: Train FastText model\n",
        "ft_model = FastText(sentences, vector_size=50, window=3, min_count=1)\n",
        "\n",
        "# Step 4: Get vector for a word\n",
        "print(\"Vector for 'love':\")\n",
        "print(ft_model.wv['love'])\n",
        "\n",
        "# Step 5: Handle unseen word (OOV)\n",
        "print(\"\\nVector for unseen word 'lovely':\")\n",
        "print(ft_model.wv['lovely'])\n",
        "\n",
        "# Step 6: Find most similar words\n",
        "print(\"\\nMost similar to 'machine':\")\n",
        "print(ft_model.wv.most_similar('machine'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8WDU8xneUqf",
        "outputId": "c667e384-3d65-41d0-ee23-4c3cf5809eee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity between 'dog' and 'cat': 0.16562882\n",
            "Similarity between 'dog' and 'fish': 0.13665016\n",
            "\n",
            "Most similar to 'cat':\n",
            "[('dog', 0.1656288504600525), ('birds', 0.1551763415336609), ('sky', 0.13940520584583282), ('the', 0.12668493390083313), ('are', 0.12119622528553009), ('swims', 0.08871668577194214), ('barks', 0.02048538811504841), ('in', 0.011042577214539051), ('water', -0.027841337025165558), ('meows', -0.03341934457421303)]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Small text corpus\n",
        "sentences = [\n",
        "    [\"dog\", \"barks\", \"at\", \"the\", \"cat\"],\n",
        "    [\"cat\", \"meows\", \"at\", \"the\", \"dog\"],\n",
        "    [\"birds\", \"are\", \"flying\", \"in\", \"the\", \"sky\"],\n",
        "    [\"fish\", \"swims\", \"in\", \"water\"]\n",
        "]\n",
        "\n",
        "# Train Word2Vec\n",
        "w2v_model = Word2Vec(sentences, vector_size=50, window=3, min_count=1, sg=1)\n",
        "\n",
        "# Word similarity\n",
        "print(\"Similarity between 'dog' and 'cat':\", w2v_model.wv.similarity(\"dog\", \"cat\"))\n",
        "print(\"Similarity between 'dog' and 'fish':\", w2v_model.wv.similarity(\"dog\", \"fish\"))\n",
        "\n",
        "# Most similar words\n",
        "print(\"\\nMost similar to 'cat':\")\n",
        "print(w2v_model.wv.most_similar(\"cat\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgICARAXeiTy",
        "outputId": "a665a5d3-e0ef-4103-9249-225803a3cdc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector for 'dog':\n",
            "[-0.00512784 -0.00174533  0.00035479  0.0010277  -0.0009202  -0.00480705\n",
            "  0.00024738 -0.00019025 -0.00260254  0.00054966]\n",
            "\n",
            "Vector for unseen word 'dogggg':\n",
            "[-0.00745251  0.00190354  0.00191593  0.00187805 -0.00046492 -0.00053973\n",
            "  0.00265135 -0.00101074  0.00162682  0.00532739]\n",
            "\n",
            "Most similar to 'dog':\n",
            "[('are', 0.19231237471103668), ('the', 0.13459865748882294), ('water', 0.11051099747419357), ('at', 0.09520871192216873), ('swims', 0.07707151025533676), ('fish', 0.04277683421969414), ('cat', 0.03962136059999466), ('in', 0.017470519989728928), ('sky', 0.01520441472530365), ('meows', -0.07853716611862183)]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Same corpus\n",
        "sentences = [\n",
        "    [\"dog\", \"barks\", \"at\", \"the\", \"cat\"],\n",
        "    [\"cat\", \"meows\", \"at\", \"the\", \"dog\"],\n",
        "    [\"birds\", \"are\", \"flying\", \"in\", \"the\", \"sky\"],\n",
        "    [\"fish\", \"swims\", \"in\", \"water\"]\n",
        "]\n",
        "\n",
        "# Train FastText\n",
        "ft_model = FastText(sentences, vector_size=50, window=3, min_count=1)\n",
        "\n",
        "# Vector for seen word\n",
        "print(\"Vector for 'dog':\")\n",
        "print(ft_model.wv['dog'][:10])  # show only first 10 dims\n",
        "\n",
        "# Vector for unseen word (OOV)\n",
        "print(\"\\nVector for unseen word 'dogggg':\")\n",
        "print(ft_model.wv['dogggg'][:10])\n",
        "\n",
        "# Most similar words\n",
        "print(\"\\nMost similar to 'dog':\")\n",
        "print(ft_model.wv.most_similar(\"dog\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S87b8lHyer2r",
        "outputId": "16260f23-cebb-4484-dc45-c17e4254a7be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analogy: king - man + woman = [('italy', 0.14145417511463165), ('dog', 0.06958038359880447), ('puppy', 0.04945472627878189), ('cat', 0.03198548033833504), ('queen', 0.012669281102716923), ('delhi', 0.0028484025970101357), ('paris', -0.030324876308441162), ('kitten', -0.0685611367225647), ('france', -0.07234222441911697), ('japan', -0.0752946138381958)]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Custom corpus for analogy\n",
        "sentences = [\n",
        "    [\"king\", \"queen\", \"man\", \"woman\"],\n",
        "    [\"paris\", \"france\", \"rome\", \"italy\"],\n",
        "    [\"delhi\", \"india\", \"tokyo\", \"japan\"],\n",
        "    [\"dog\", \"puppy\", \"cat\", \"kitten\"]\n",
        "]\n",
        "\n",
        "# Train model\n",
        "model = Word2Vec(sentences, vector_size=50, window=3, min_count=1, sg=1)\n",
        "\n",
        "# Analogy: king - man + woman â‰ˆ queen\n",
        "result = model.wv.most_similar(positive=[\"king\", \"woman\"], negative=[\"man\"])\n",
        "print(\"Analogy: king - man + woman =\", result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-50eEzeseyML",
        "outputId": "9d6ba666-2608-4fed-b25b-2cccd40ec612"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Most similar to 'playing': [('play', 0.43791663646698), ('runner', 0.28430938720703125), ('played', 0.28360700607299805), ('run', 0.18218275904655457), ('running', 0.1550898253917694), ('player', 0.14196591079235077), ('studied', 0.01624378375709057), ('ran', -0.06368699669837952), ('student', -0.11292298883199692), ('studying', -0.137682244181633)]\n",
            "Most similar to 'runner': [('run', 0.5079447031021118), ('running', 0.47139981389045715), ('playing', 0.284309446811676), ('played', 0.27585023641586304), ('player', 0.20748484134674072), ('play', 0.17613056302070618), ('ran', 0.12243297696113586), ('studied', 0.03735663741827011), ('study', -0.0896022692322731), ('studying', -0.1674293577671051)]\n",
            "\n",
            "Vector for unseen word 'playyyyyy':\n",
            "[-2.3022487e-03 -3.2724833e-04 -1.9040132e-03  5.2393098e-05\n",
            "  2.7455350e-03 -4.2905905e-03  3.1240331e-03 -2.0504657e-03\n",
            " -2.5947457e-03 -2.2385521e-03]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "sentences = [\n",
        "    [\"play\", \"playing\", \"played\", \"player\"],\n",
        "    [\"run\", \"running\", \"runner\", \"ran\"],\n",
        "    [\"study\", \"studying\", \"studied\", \"student\"]\n",
        "]\n",
        "\n",
        "# Train FastText\n",
        "ft_model = FastText(sentences, vector_size=50, window=3, min_count=1)\n",
        "\n",
        "# Similar words\n",
        "print(\"Most similar to 'playing':\", ft_model.wv.most_similar(\"playing\"))\n",
        "print(\"Most similar to 'runner':\", ft_model.wv.most_similar(\"runner\"))\n",
        "\n",
        "# Test unseen but related word\n",
        "print(\"\\nVector for unseen word 'playyyyyy':\")\n",
        "print(ft_model.wv['playyyyyy'][:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKysDFtufJwV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
