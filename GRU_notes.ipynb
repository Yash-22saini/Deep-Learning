{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "GRU (Gated Recurrent Unit) is a type of Recurrent Neural Network (RNN) architecture designed to solve two main problems of traditional RNNs:\n",
        "\n",
        "Vanishing gradient\n",
        "\n",
        "Difficulty in capturing long-term dependencies\n",
        "\n",
        "It is a simplified version of LSTM (Long Short-Term Memory) with fewer gates and parameters."
      ],
      "metadata": {
        "id": "ENOyLy-uvdHw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why GRU?\n",
        "\n",
        "RNNs struggle with long sequences — they forget earlier information.\n",
        "\n",
        "LSTMs solve this but are computationally heavy (3 gates).\n",
        "\n",
        "GRU simplifies this — 2 gates instead of 3 — while keeping performance close to LSTM.\n"
      ],
      "metadata": {
        "id": "yMJ6dLhKvdkb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A GRU cell has:\n",
        "\n",
        "Update Gate (zₜ)\n",
        "\n",
        "Reset Gate (rₜ)\n",
        "\n",
        "Candidate Hidden State (ĥₜ)\n",
        "\n",
        "Final Hidden State (hₜ)"
      ],
      "metadata": {
        "id": "knQB_lOovd5O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gate\t           \n",
        "Update Gate (zₜ)\n",
        "Controls how much past info to carry forward (like LSTM’s forget + input gate combined).\n",
        "\n",
        "Reset Gate (rₜ)\tControls how much past info to forget.\n",
        "\n",
        "Candidate Hidden (ĥₜ)\tNew memory content.\n",
        "\n",
        "Final Hidden (hₜ)\tOutput for current time step."
      ],
      "metadata": {
        "id": "_jQ4A9FDv0j1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Advantages of GRU\n",
        "\n",
        "✅ Solves vanishing gradient problem\n",
        "\n",
        "✅ Faster and simpler than LSTM\n",
        "\n",
        "✅ Performs well on moderate-length sequences\n",
        "\n",
        "✅ Requires less memory and data\n",
        "\n",
        "Disadvantages of GRU\n",
        "\n",
        "❌ Can underperform LSTM on very long sequences\n",
        "\n",
        "❌ No separate cell state (less control over memory)"
      ],
      "metadata": {
        "id": "mj9RGhyMv_4C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Real-World Use Cases\n",
        "\n",
        "Speech Recognition\n",
        "\n",
        "Time Series Forecasting\n",
        "\n",
        "Sentiment Analysis\n",
        "\n",
        "Stock Price Prediction\n",
        "\n",
        "Machine Translation"
      ],
      "metadata": {
        "id": "F-rSj2hewPLD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LlQn5Xr-wPvU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}